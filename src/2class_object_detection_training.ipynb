{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "papermill": {
      "duration": 5672.030464,
      "end_time": "2020-12-03T21:15:43.903691",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2020-12-03T19:41:11.873227",
      "version": "2.1.0"
    },
    "colab": {
      "name": "2class-object-detection-training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.016133,
          "end_time": "2020-12-03T19:41:16.277625",
          "exception": false,
          "start_time": "2020-12-03T19:41:16.261492",
          "status": "completed"
        },
        "tags": [],
        "id": "SbAt3SlE5Qu8"
      },
      "source": [
        "This notebook detects 2 class objects.\n",
        "- class1: helmet without impact\n",
        "- class2: helmet with impact\n",
        "\n",
        "Object Detection part is based on [EfficientDet notebook](https://www.kaggle.com/shonenkov/training-efficientdet) for [global wheat detection competition](https://www.kaggle.com/c/global-wheat-detection) by [shonenkov](https://www.kaggle.com/shonenkov), which is using [github repos efficientdet-pytorch](https://github.com/rwightman/efficientdet-pytorch) by [@rwightman](https://www.kaggle.com/rwightman).\n",
        "\n",
        "Inference part can be foud [here](https://www.kaggle.com/its7171/2class-object-detection-inference/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkvTg6_c6Cj0"
      },
      "source": [
        "Kaggle = False\n",
        "Colab = !Kaggle"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmIZ8aCDBp6-",
        "outputId": "622207b4-9d34-4479-eb6f-c14248b16e96"
      },
      "source": [
        "import os, sys\n",
        "from pathlib import Path\n",
        "\n",
        "if Colab:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    path = \"/content/drive/My Drive\"\n",
        "    os.chdir(path)\n",
        "    os.listdir(path)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "execution": {
          "iopub.execute_input": "2020-12-03T19:41:16.315908Z",
          "iopub.status.busy": "2020-12-03T19:41:16.314887Z",
          "iopub.status.idle": "2020-12-03T19:41:47.853592Z",
          "shell.execute_reply": "2020-12-03T19:41:47.852000Z"
        },
        "papermill": {
          "duration": 31.561437,
          "end_time": "2020-12-03T19:41:47.853762",
          "exception": false,
          "start_time": "2020-12-03T19:41:16.292325",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b33SLkXj5Qu8",
        "outputId": "780b1226-28f8-4f2a-9539-e8a94a386850"
      },
      "source": [
        "if Kaggle:\n",
        "    !pip install ../input/nfl-lib/timm-0.1.26-py3-none-any.whl\n",
        "    !tar xfz ../input/nfl-lib/pkgs.tgz\n",
        "else:\n",
        "    !pip install NFL/nfl-lib/timm-0.1.26-py3-none-any.whl\n",
        "    !tar xfz NFL/nfl-lib/pkgs.tgz    \n",
        "    !pip install albumentations==0.4.6\n",
        "# for pytorch1.6\n",
        "cmd = \"sed -i -e 's/ \\/ / \\/\\/ /' timm-efficientdet-pytorch/effdet/bench.py\"\n",
        "!$cmd"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: timm==0.1.26 from file:///content/drive/My%20Drive/NFL/nfl-lib/timm-0.1.26-py3-none-any.whl in /usr/local/lib/python3.6/dist-packages (0.1.26)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from timm==0.1.26) (0.8.1+cu101)\n",
            "Requirement already satisfied: torch>=1.0 in /usr/local/lib/python3.6/dist-packages (from timm==0.1.26) (1.7.0+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision->timm==0.1.26) (1.18.5)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision->timm==0.1.26) (7.0.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.0->timm==0.1.26) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=1.0->timm==0.1.26) (0.16.0)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.0->timm==0.1.26) (0.8)\n",
            "Requirement already satisfied: albumentations==0.4.6 in /usr/local/lib/python3.6/dist-packages (0.4.6)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from albumentations==0.4.6) (3.13)\n",
            "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from albumentations==0.4.6) (1.18.5)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from albumentations==0.4.6) (4.1.2.30)\n",
            "Requirement already satisfied: imgaug>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from albumentations==0.4.6) (0.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from albumentations==0.4.6) (1.4.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (7.0.0)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.7.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.15.0)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (2.4.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (3.2.2)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (0.16.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (1.3.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (2.4.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (2.8.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2.5)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (1.1.1)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (4.4.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-input": true,
        "_kg_hide-output": true,
        "execution": {
          "iopub.execute_input": "2020-12-03T19:41:47.900849Z",
          "iopub.status.busy": "2020-12-03T19:41:47.899850Z",
          "iopub.status.idle": "2020-12-03T19:41:51.320552Z",
          "shell.execute_reply": "2020-12-03T19:41:51.319742Z"
        },
        "papermill": {
          "duration": 3.449721,
          "end_time": "2020-12-03T19:41:51.320687",
          "exception": false,
          "start_time": "2020-12-03T19:41:47.870966",
          "status": "completed"
        },
        "tags": [],
        "id": "KquhUKBI5Qu9"
      },
      "source": [
        "import sys\n",
        "sys.path.insert(0, \"timm-efficientdet-pytorch\")\n",
        "sys.path.insert(0, \"omegaconf\")\n",
        "\n",
        "import torch\n",
        "import os\n",
        "from datetime import datetime\n",
        "import time\n",
        "import random\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import albumentations as A\n",
        "import matplotlib.pyplot as plt\n",
        "from albumentations.pytorch.transforms import ToTensorV2\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from torch.utils.data.sampler import SequentialSampler, RandomSampler\n",
        "from glob import glob\n",
        "import pandas as pd\n",
        "from effdet import get_efficientdet_config, EfficientDet, DetBenchTrain\n",
        "from effdet.efficientdet import HeadNet\n",
        "from tqdm import tqdm\n",
        "\n",
        "SEED = 42\n",
        "\n",
        "def seed_everything(seed):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "seed_everything(SEED)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.015808,
          "end_time": "2020-12-03T19:41:51.352887",
          "exception": false,
          "start_time": "2020-12-03T19:41:51.337079",
          "status": "completed"
        },
        "tags": [],
        "id": "DVwFB2QR5Qu9"
      },
      "source": [
        "# Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUPe5jAeDhXM"
      },
      "source": [
        "if Kaggle:\n",
        "    BASEPATH = \"../input/nfl-impact-detection\"\n",
        "    outdir = '.'\n",
        "    TRAIN_IMGPATH = outdir\n",
        "else:\n",
        "    PATH = 'NFL/'\n",
        "    BASEPATH = PATH + 'Data'\n",
        "    TRAIN_IMGPATH = BASEPATH\n",
        "    outdir = Path(PATH+'res')\n",
        "    if not os.path.exists(outdir):\n",
        "        os.mkdir(outdir)\n",
        "    outdir = Path(PATH+'res/efficientDet-res')\n",
        "    if not os.path.exists(outdir):\n",
        "        os.mkdir(outdir)\n",
        "    MODELNAME = \"ED5-512\"\n",
        "    VERSION = '{}'.format(MODELNAME)\n",
        "    outdir = os.path.join(outdir, VERSION)\n",
        "    if not os.path.exists(outdir):\n",
        "        os.mkdir(outdir)\n",
        "    # from datetime import datetime, timedelta\n",
        "    # dateTimeObj = datetime.now()\n",
        "    # timestampStr = dateTimeObj.strftime(\"%d-%b-%Y-%H\")\n",
        "    # modelpath = os.path.join(outdir, 'all-kfold-hairaug-456-norm-metanew-b16')\n",
        "    timestampStr = 'org-epoch20-lre-3'\n",
        "    outdir = os.path.join(outdir, timestampStr)\n",
        "    if not os.path.exists(outdir):\n",
        "        os.mkdir(outdir)  "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-12-03T19:41:51.397809Z",
          "iopub.status.busy": "2020-12-03T19:41:51.397205Z",
          "iopub.status.idle": "2020-12-03T19:54:33.739582Z",
          "shell.execute_reply": "2020-12-03T19:54:33.739088Z"
        },
        "papermill": {
          "duration": 762.371229,
          "end_time": "2020-12-03T19:54:33.739714",
          "exception": false,
          "start_time": "2020-12-03T19:41:51.368485",
          "status": "completed"
        },
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "0QPqdU4t5Qu9",
        "outputId": "7e1b612a-7ee7-4c55-e94e-6f62cba95003"
      },
      "source": [
        "# video_labels = pd.read_csv(os.path.join(BASEPATH, 'train_labels.csv')).fillna(0)\n",
        "# video_labels_with_impact = video_labels[video_labels['impact'] > 0]\n",
        "# for row in tqdm(video_labels_with_impact[['video','frame','label']].values):\n",
        "#     frames = np.array([-4,-3,-2,-1,1,2,3,4])+row[1]\n",
        "#     video_labels.loc[(video_labels['video'] == row[0]) \n",
        "#                                  & (video_labels['frame'].isin(frames))\n",
        "#                                  & (video_labels['label'] == row[2]), 'impact'] = 1\n",
        "# video_labels['image_name'] = video_labels['video'].str.replace('.mp4', '') + '_' + video_labels['frame'].astype(str) + '.png'\n",
        "# video_labels = video_labels[video_labels.groupby('image_name')['impact'].transform(\"sum\") > 0].reset_index(drop=True)\n",
        "# video_labels['impact'] = video_labels['impact'].astype(int)+1\n",
        "# video_labels['x'] = video_labels['left']\n",
        "# video_labels['y'] = video_labels['top']\n",
        "# video_labels['w'] = video_labels['width']\n",
        "# video_labels['h'] = video_labels['height']\n",
        "# video_labels.head()\n",
        "\n",
        "video_labels = pd.read_csv(os.path.join(BASEPATH,'video_labels.csv'), index_col=0)\n",
        "display(video_labels.head())\n",
        "print(video_labels.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gameKey</th>\n",
              "      <th>playID</th>\n",
              "      <th>view</th>\n",
              "      <th>video</th>\n",
              "      <th>frame</th>\n",
              "      <th>label</th>\n",
              "      <th>left</th>\n",
              "      <th>width</th>\n",
              "      <th>top</th>\n",
              "      <th>height</th>\n",
              "      <th>impact</th>\n",
              "      <th>impactType</th>\n",
              "      <th>confidence</th>\n",
              "      <th>visibility</th>\n",
              "      <th>image_name</th>\n",
              "      <th>x</th>\n",
              "      <th>y</th>\n",
              "      <th>w</th>\n",
              "      <th>h</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>57583</td>\n",
              "      <td>82</td>\n",
              "      <td>Endzone</td>\n",
              "      <td>57583_000082_Endzone.mp4</td>\n",
              "      <td>34</td>\n",
              "      <td>V73</td>\n",
              "      <td>655</td>\n",
              "      <td>21</td>\n",
              "      <td>331</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>57583_000082_Endzone_34.png</td>\n",
              "      <td>655</td>\n",
              "      <td>331</td>\n",
              "      <td>21</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>57583</td>\n",
              "      <td>82</td>\n",
              "      <td>Endzone</td>\n",
              "      <td>57583_000082_Endzone.mp4</td>\n",
              "      <td>34</td>\n",
              "      <td>H99</td>\n",
              "      <td>583</td>\n",
              "      <td>21</td>\n",
              "      <td>312</td>\n",
              "      <td>30</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>57583_000082_Endzone_34.png</td>\n",
              "      <td>583</td>\n",
              "      <td>312</td>\n",
              "      <td>21</td>\n",
              "      <td>30</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>57583</td>\n",
              "      <td>82</td>\n",
              "      <td>Endzone</td>\n",
              "      <td>57583_000082_Endzone.mp4</td>\n",
              "      <td>34</td>\n",
              "      <td>V15</td>\n",
              "      <td>1069</td>\n",
              "      <td>22</td>\n",
              "      <td>301</td>\n",
              "      <td>20</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>57583_000082_Endzone_34.png</td>\n",
              "      <td>1069</td>\n",
              "      <td>301</td>\n",
              "      <td>22</td>\n",
              "      <td>20</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>57583</td>\n",
              "      <td>82</td>\n",
              "      <td>Endzone</td>\n",
              "      <td>57583_000082_Endzone.mp4</td>\n",
              "      <td>34</td>\n",
              "      <td>H97</td>\n",
              "      <td>402</td>\n",
              "      <td>21</td>\n",
              "      <td>313</td>\n",
              "      <td>29</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>57583_000082_Endzone_34.png</td>\n",
              "      <td>402</td>\n",
              "      <td>313</td>\n",
              "      <td>21</td>\n",
              "      <td>29</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>57583</td>\n",
              "      <td>82</td>\n",
              "      <td>Endzone</td>\n",
              "      <td>57583_000082_Endzone.mp4</td>\n",
              "      <td>34</td>\n",
              "      <td>V72</td>\n",
              "      <td>445</td>\n",
              "      <td>21</td>\n",
              "      <td>328</td>\n",
              "      <td>16</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>57583_000082_Endzone_34.png</td>\n",
              "      <td>445</td>\n",
              "      <td>328</td>\n",
              "      <td>21</td>\n",
              "      <td>16</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   gameKey  playID     view                     video  ...     x    y   w   h\n",
              "0    57583      82  Endzone  57583_000082_Endzone.mp4  ...   655  331  21  15\n",
              "1    57583      82  Endzone  57583_000082_Endzone.mp4  ...   583  312  21  30\n",
              "2    57583      82  Endzone  57583_000082_Endzone.mp4  ...  1069  301  22  20\n",
              "3    57583      82  Endzone  57583_000082_Endzone.mp4  ...   402  313  21  29\n",
              "4    57583      82  Endzone  57583_000082_Endzone.mp4  ...   445  328  21  16\n",
              "\n",
              "[5 rows x 19 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "(197838, 19)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LB91hjvzSIcI"
      },
      "source": [
        "# display(video_labels.head())\n",
        "# print(video_labels.shape)\n",
        "# video_labels.to_csv(os.path.join(BASEPATH,'video_labels.csv'), index=False)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-12-03T19:54:35.361621Z",
          "iopub.status.busy": "2020-12-03T19:54:35.360784Z",
          "iopub.status.idle": "2020-12-03T19:54:35.468122Z",
          "shell.execute_reply": "2020-12-03T19:54:35.467547Z"
        },
        "papermill": {
          "duration": 0.925308,
          "end_time": "2020-12-03T19:54:35.468243",
          "exception": false,
          "start_time": "2020-12-03T19:54:34.542935",
          "status": "completed"
        },
        "tags": [],
        "id": "d8dFJux45Qu9"
      },
      "source": [
        "np.random.seed(0)\n",
        "video_names = np.random.permutation(video_labels.video.unique())\n",
        "valid_video_len = int(len(video_names)*0.2)\n",
        "video_valid = video_names[:valid_video_len]\n",
        "video_train = video_names[valid_video_len:]\n",
        "images_valid = video_labels[ video_labels.video.isin(video_valid)].image_name.unique()\n",
        "images_train = video_labels[~video_labels.video.isin(video_valid)].image_name.unique()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-12-03T19:54:37.083220Z",
          "iopub.status.busy": "2020-12-03T19:54:37.081252Z",
          "iopub.status.idle": "2020-12-03T19:54:37.083913Z",
          "shell.execute_reply": "2020-12-03T19:54:37.084380Z"
        },
        "papermill": {
          "duration": 0.814812,
          "end_time": "2020-12-03T19:54:37.084502",
          "exception": false,
          "start_time": "2020-12-03T19:54:36.269690",
          "status": "completed"
        },
        "tags": [],
        "id": "JASx4ztJ5Qu-"
      },
      "source": [
        "def mk_images(video_name, video_labels, video_dir, out_dir, only_with_impact=True):\n",
        "    video_path=f\"{video_dir}/{video_name}\"\n",
        "    video_name = os.path.basename(video_path)\n",
        "    vidcap = cv2.VideoCapture(video_path)\n",
        "    if only_with_impact:\n",
        "        boxes_all = video_labels.query(\"video == @video_name\")\n",
        "        print(video_path, boxes_all[boxes_all.impact > 1.0].shape[0])\n",
        "    else:\n",
        "        print(video_path)\n",
        "    frame = 0\n",
        "    while True:\n",
        "        it_worked, img = vidcap.read()\n",
        "        if not it_worked:\n",
        "            break\n",
        "        frame += 1\n",
        "        if only_with_impact:\n",
        "            boxes = video_labels.query(\"video == @video_name and frame == @frame\")\n",
        "            boxes_with_impact = boxes[boxes.impact > 1.0]\n",
        "            if boxes_with_impact.shape[0] == 0:\n",
        "                continue\n",
        "        img_name = f\"{video_name}_frame{frame}\"\n",
        "        image_path = f'{out_dir}/{video_name}'.replace('.mp4',f'_{frame}.png')\n",
        "        _ = cv2.imwrite(image_path, img)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "_kg_hide-output": true,
        "execution": {
          "iopub.execute_input": "2020-12-03T19:54:38.758603Z",
          "iopub.status.busy": "2020-12-03T19:54:38.757834Z",
          "iopub.status.idle": "2020-12-03T20:17:19.848931Z",
          "shell.execute_reply": "2020-12-03T20:17:19.848179Z"
        },
        "papermill": {
          "duration": 1361.975668,
          "end_time": "2020-12-03T20:17:19.849108",
          "exception": false,
          "start_time": "2020-12-03T19:54:37.873440",
          "status": "completed"
        },
        "tags": [],
        "id": "mF1JI58F5Qu-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c99e6851-b33e-4507-d3be-878b820e1391"
      },
      "source": [
        "uniq_video = video_labels.video.unique()\n",
        "# video_dir = '/kaggle/input/nfl-impact-detection/train'\n",
        "video_dir = os.path.join(BASEPATH, 'train')\n",
        "out_dir = os.path.join(TRAIN_IMGPATH, 'train_images')\n",
        "print(out_dir)\n",
        "# !mkdir -p $out_dir\n",
        "# for video_name in uniq_video:\n",
        "#     mk_images(video_name, video_labels, video_dir, out_dir)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "NFL/Data/train_images\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 1.116956,
          "end_time": "2020-12-03T20:17:21.805986",
          "exception": false,
          "start_time": "2020-12-03T20:17:20.689030",
          "status": "completed"
        },
        "tags": [],
        "id": "uZDPyNTA5Qu-"
      },
      "source": [
        "## Albumentations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-12-03T20:17:23.531452Z",
          "iopub.status.busy": "2020-12-03T20:17:23.529545Z",
          "iopub.status.idle": "2020-12-03T20:17:23.535342Z",
          "shell.execute_reply": "2020-12-03T20:17:23.534636Z"
        },
        "papermill": {
          "duration": 0.894654,
          "end_time": "2020-12-03T20:17:23.535470",
          "exception": false,
          "start_time": "2020-12-03T20:17:22.640816",
          "status": "completed"
        },
        "tags": [],
        "id": "RBeM0iN85Qu-"
      },
      "source": [
        "def get_train_transforms():\n",
        "    return A.Compose(\n",
        "        [\n",
        "            A.HorizontalFlip(p=0.5),\n",
        "            A.Resize(height=512, width=512, p=1),\n",
        "            ToTensorV2(p=1.0),\n",
        "        ], \n",
        "        p=1.0, \n",
        "        bbox_params=A.BboxParams(\n",
        "            format='pascal_voc',\n",
        "            min_area=0, \n",
        "            min_visibility=0,\n",
        "            label_fields=['labels']\n",
        "        )\n",
        "    )\n",
        "\n",
        "def get_valid_transforms():\n",
        "    return A.Compose(\n",
        "        [\n",
        "            A.Resize(height=512, width=512, p=1.0),\n",
        "            ToTensorV2(p=1.0),\n",
        "        ], \n",
        "        p=1.0, \n",
        "        bbox_params=A.BboxParams(\n",
        "            format='pascal_voc',\n",
        "            min_area=0, \n",
        "            min_visibility=0,\n",
        "            label_fields=['labels']\n",
        "        )\n",
        "    )"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.860904,
          "end_time": "2020-12-03T20:17:25.233882",
          "exception": false,
          "start_time": "2020-12-03T20:17:24.372978",
          "status": "completed"
        },
        "tags": [],
        "id": "gYqmaqmX5Qu-"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-12-03T20:17:27.167718Z",
          "iopub.status.busy": "2020-12-03T20:17:27.166491Z",
          "iopub.status.idle": "2020-12-03T20:17:27.179341Z",
          "shell.execute_reply": "2020-12-03T20:17:27.178834Z"
        },
        "papermill": {
          "duration": 1.00411,
          "end_time": "2020-12-03T20:17:27.179451",
          "exception": false,
          "start_time": "2020-12-03T20:17:26.175341",
          "status": "completed"
        },
        "tags": [],
        "id": "PpEmFOv55Qu-"
      },
      "source": [
        "TRAIN_ROOT_PATH = os.path.join(TRAIN_IMGPATH, 'train_images')\n",
        "\n",
        "class DatasetRetriever(Dataset):\n",
        "\n",
        "    def __init__(self, marking, image_ids, transforms=None, test=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.image_ids = image_ids\n",
        "        self.marking = marking\n",
        "        self.transforms = transforms\n",
        "        self.test = test\n",
        "\n",
        "    def __getitem__(self, index: int):\n",
        "        image_id = self.image_ids[index]\n",
        "        \n",
        "        image, boxes, labels = self.load_image_and_boxes(index)\n",
        "        \n",
        "        target = {}\n",
        "        target['boxes'] = boxes\n",
        "        target['labels'] = torch.tensor(labels)\n",
        "        target['image_id'] = torch.tensor([index])\n",
        "\n",
        "        if self.transforms:\n",
        "            for i in range(10):\n",
        "                sample = self.transforms(**{\n",
        "                    'image': image,\n",
        "                    'bboxes': target['boxes'],\n",
        "                    'labels': labels\n",
        "                })\n",
        "                if len(sample['bboxes']) > 0:\n",
        "                    image = sample['image']\n",
        "                    target['boxes'] = torch.stack(tuple(map(torch.tensor, zip(*sample['bboxes'])))).permute(1, 0)\n",
        "                    target['boxes'][:,[0,1,2,3]] = target['boxes'][:,[1,0,3,2]]  #yxyx: be warning\n",
        "                    break\n",
        "        return image, target, image_id\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return self.image_ids.shape[0]\n",
        "\n",
        "    def load_image_and_boxes(self, index):\n",
        "        image_id = self.image_ids[index]\n",
        "        # print(f'{TRAIN_ROOT_PATH}/{image_id}')\n",
        "        image = cv2.imread(f'{TRAIN_ROOT_PATH}/{image_id}', cv2.IMREAD_COLOR).copy().astype(np.float32)\n",
        "        # img = cv2.imread(f'{TRAIN_ROOT_PATH}/{image_id}', cv2.IMREAD_COLOR)\n",
        "        # if img is NoneType:\n",
        "        #     print(f'{TRAIN_ROOT_PATH}/{image_id}')\n",
        "        # image = img.copy().astype(np.float32)\n",
        "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
        "        image /= 255.0\n",
        "        records = self.marking[self.marking['image_name'] == image_id]\n",
        "        boxes = records[['x', 'y', 'w', 'h']].values\n",
        "        boxes[:, 2] = boxes[:, 0] + boxes[:, 2]\n",
        "        boxes[:, 3] = boxes[:, 1] + boxes[:, 3]\n",
        "        labels = records['impact'].values\n",
        "        return image, boxes, labels"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-12-03T20:17:29.786515Z",
          "iopub.status.busy": "2020-12-03T20:17:29.785545Z",
          "iopub.status.idle": "2020-12-03T20:17:29.787381Z",
          "shell.execute_reply": "2020-12-03T20:17:29.788067Z"
        },
        "papermill": {
          "duration": 1.299025,
          "end_time": "2020-12-03T20:17:29.788236",
          "exception": false,
          "start_time": "2020-12-03T20:17:28.489211",
          "status": "completed"
        },
        "tags": [],
        "id": "zfBRK8395Qu-"
      },
      "source": [
        "train_dataset = DatasetRetriever(\n",
        "    image_ids=images_train,\n",
        "    marking=video_labels,\n",
        "    transforms=get_train_transforms(),\n",
        "    test=False,\n",
        ")\n",
        "\n",
        "validation_dataset = DatasetRetriever(\n",
        "    image_ids=images_valid,\n",
        "    marking=video_labels,\n",
        "    transforms=get_valid_transforms(),\n",
        "    test=True,\n",
        ")"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "papermill": {
          "duration": 0.854518,
          "end_time": "2020-12-03T20:17:31.516845",
          "exception": false,
          "start_time": "2020-12-03T20:17:30.662327",
          "status": "completed"
        },
        "tags": [],
        "id": "fR6RQZ_B5Qu-"
      },
      "source": [
        "## Fitter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-12-03T20:17:33.240203Z",
          "iopub.status.busy": "2020-12-03T20:17:33.238373Z",
          "iopub.status.idle": "2020-12-03T20:17:33.240858Z",
          "shell.execute_reply": "2020-12-03T20:17:33.241329Z"
        },
        "papermill": {
          "duration": 0.857125,
          "end_time": "2020-12-03T20:17:33.241450",
          "exception": false,
          "start_time": "2020-12-03T20:17:32.384325",
          "status": "completed"
        },
        "tags": [],
        "id": "2Ds6QgCh5Qu-"
      },
      "source": [
        "class AverageMeter(object):\n",
        "    \"\"\"Computes and stores the average and current value\"\"\"\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-12-03T20:17:34.928263Z",
          "iopub.status.busy": "2020-12-03T20:17:34.893824Z",
          "iopub.status.idle": "2020-12-03T20:17:34.943197Z",
          "shell.execute_reply": "2020-12-03T20:17:34.942605Z"
        },
        "papermill": {
          "duration": 0.879671,
          "end_time": "2020-12-03T20:17:34.943328",
          "exception": false,
          "start_time": "2020-12-03T20:17:34.063657",
          "status": "completed"
        },
        "tags": [],
        "id": "pY_EQeAl5Qu-"
      },
      "source": [
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "class Fitter:\n",
        "    \n",
        "    def __init__(self, model, device, config):\n",
        "        self.config = config\n",
        "        self.epoch = 0\n",
        "\n",
        "        self.base_dir = f'./{config.folder}'\n",
        "        if not os.path.exists(self.base_dir):\n",
        "            os.makedirs(self.base_dir)\n",
        "        \n",
        "        self.log_path = f'{self.base_dir}/log.txt'\n",
        "        self.best_summary_loss = 10**5\n",
        "\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "\n",
        "        param_optimizer = list(self.model.named_parameters())\n",
        "        no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "        optimizer_grouped_parameters = [\n",
        "            {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.001},\n",
        "            {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "        ] \n",
        "\n",
        "        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=config.lr)\n",
        "        self.scheduler = config.SchedulerClass(self.optimizer, **config.scheduler_params)\n",
        "        self.log(f'Fitter prepared. Device is {self.device}')\n",
        "\n",
        "    def fit(self, train_loader, validation_loader):\n",
        "        for e in range(self.config.n_epochs):\n",
        "            if self.config.verbose:\n",
        "                lr = self.optimizer.param_groups[0]['lr']\n",
        "                timestamp = datetime.utcnow().isoformat()\n",
        "                self.log(f'\\n{timestamp}\\nLR: {lr}')\n",
        "\n",
        "            t = time.time()\n",
        "            summary_loss = self.train_one_epoch(train_loader)\n",
        "\n",
        "            self.log(f'[RESULT]: Train. Epoch: {self.epoch}, summary_loss: {summary_loss.avg:.5f}, time: {(time.time() - t):.5f}')\n",
        "            self.save(f'{self.base_dir}/last-checkpoint.bin')\n",
        "\n",
        "            t = time.time()\n",
        "            summary_loss = self.validation(validation_loader)\n",
        "\n",
        "            self.log(f'[RESULT]: Val. Epoch: {self.epoch}, summary_loss: {summary_loss.avg:.5f}, time: {(time.time() - t):.5f}')\n",
        "            if summary_loss.avg < self.best_summary_loss:\n",
        "                self.best_summary_loss = summary_loss.avg\n",
        "                self.model.eval()\n",
        "                self.save(f'{self.base_dir}/best-checkpoint-{str(self.epoch).zfill(3)}epoch.bin')\n",
        "                for path in sorted(glob(f'{self.base_dir}/best-checkpoint-*epoch.bin'))[:-3]:\n",
        "                    os.remove(path)\n",
        "\n",
        "            if self.config.validation_scheduler:\n",
        "                self.scheduler.step(metrics=summary_loss.avg)\n",
        "\n",
        "            self.epoch += 1\n",
        "\n",
        "    def validation(self, val_loader):\n",
        "        self.model.eval()\n",
        "        summary_loss = AverageMeter()\n",
        "        t = time.time()\n",
        "        for step, (images, targets, image_ids) in enumerate(val_loader):\n",
        "            if self.config.verbose:\n",
        "                if step % self.config.verbose_step == 0:\n",
        "                    print(\n",
        "                        f'Val Step {step}/{len(val_loader)}, ' + \\\n",
        "                        f'summary_loss: {summary_loss.avg:.5f}, ' + \\\n",
        "                        f'time: {(time.time() - t):.5f}', end='\\r'\n",
        "                    )\n",
        "            with torch.no_grad():\n",
        "                images = torch.stack(images)\n",
        "                batch_size = images.shape[0]\n",
        "                images = images.to(self.device).float()\n",
        "                boxes = [target['boxes'].to(self.device).float() for target in targets]\n",
        "                labels = [target['labels'].to(self.device).float() for target in targets]\n",
        "\n",
        "                loss, _, _ = self.model(images, boxes, labels)\n",
        "                summary_loss.update(loss.detach().item(), batch_size)\n",
        "\n",
        "        return summary_loss\n",
        "\n",
        "    def train_one_epoch(self, train_loader):\n",
        "        self.model.train()\n",
        "        summary_loss = AverageMeter()\n",
        "        t = time.time()\n",
        "        for step, (images, targets, image_ids) in enumerate(train_loader):\n",
        "            if self.config.verbose:\n",
        "                if step % self.config.verbose_step == 0:\n",
        "                    print(\n",
        "                        f'Train Step {step}/{len(train_loader)}, ' + \\\n",
        "                        f'summary_loss: {summary_loss.avg:.5f}, ' + \\\n",
        "                        f'time: {(time.time() - t):.5f}', end='\\r'\n",
        "                    )\n",
        "            \n",
        "            images = torch.stack(images)\n",
        "            images = images.to(self.device).float()\n",
        "            batch_size = images.shape[0]\n",
        "            boxes = [target['boxes'].to(self.device).float() for target in targets]\n",
        "            labels = [target['labels'].to(self.device).float() for target in targets]\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            \n",
        "            loss, _, _ = self.model(images, boxes, labels)\n",
        "            \n",
        "            loss.backward()\n",
        "\n",
        "            summary_loss.update(loss.detach().item(), batch_size)\n",
        "\n",
        "            self.optimizer.step()\n",
        "\n",
        "            if self.config.step_scheduler:\n",
        "                self.scheduler.step()\n",
        "\n",
        "        return summary_loss\n",
        "    \n",
        "    def save(self, path):\n",
        "        self.model.eval()\n",
        "        torch.save({\n",
        "            'model_state_dict': self.model.model.state_dict(),\n",
        "            'optimizer_state_dict': self.optimizer.state_dict(),\n",
        "            'scheduler_state_dict': self.scheduler.state_dict(),\n",
        "            'best_summary_loss': self.best_summary_loss,\n",
        "            'epoch': self.epoch,\n",
        "        }, path)\n",
        "\n",
        "    def load(self, path):\n",
        "        checkpoint = torch.load(path)\n",
        "        self.model.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "        self.scheduler.load_state_dict(checkpoint['scheduler_state_dict'])\n",
        "        self.best_summary_loss = checkpoint['best_summary_loss']\n",
        "        self.epoch = checkpoint['epoch'] + 1\n",
        "        \n",
        "    def log(self, message):\n",
        "        if self.config.verbose:\n",
        "            print(message)\n",
        "        with open(self.log_path, 'a+') as logger:\n",
        "            logger.write(f'{message}\\n')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-12-03T20:17:36.640201Z",
          "iopub.status.busy": "2020-12-03T20:17:36.639432Z",
          "iopub.status.idle": "2020-12-03T20:17:36.643624Z",
          "shell.execute_reply": "2020-12-03T20:17:36.643063Z"
        },
        "papermill": {
          "duration": 0.840689,
          "end_time": "2020-12-03T20:17:36.643746",
          "exception": false,
          "start_time": "2020-12-03T20:17:35.803057",
          "status": "completed"
        },
        "tags": [],
        "id": "Qu5pIEq85Qu-"
      },
      "source": [
        "class TrainGlobalConfig:\n",
        "    num_workers = 4\n",
        "    batch_size = 4 \n",
        "    n_epochs = 20\n",
        "    lr = 0.0001\n",
        "    folder = os.path.join(outdir, 'effdet5-models')\n",
        "    verbose = True\n",
        "    verbose_step = 1\n",
        "    step_scheduler = False\n",
        "    validation_scheduler = True\n",
        "    SchedulerClass = torch.optim.lr_scheduler.ReduceLROnPlateau\n",
        "    scheduler_params = dict(\n",
        "        mode='min',\n",
        "        factor=0.5,\n",
        "        patience=1,\n",
        "        verbose=False, \n",
        "        threshold=0.0001,\n",
        "        threshold_mode='abs',\n",
        "        cooldown=0, \n",
        "        min_lr=1e-8,\n",
        "        eps=1e-08\n",
        "    )"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-12-03T20:17:38.345119Z",
          "iopub.status.busy": "2020-12-03T20:17:38.344232Z",
          "iopub.status.idle": "2020-12-03T20:17:38.347364Z",
          "shell.execute_reply": "2020-12-03T20:17:38.346780Z"
        },
        "papermill": {
          "duration": 0.856628,
          "end_time": "2020-12-03T20:17:38.347461",
          "exception": false,
          "start_time": "2020-12-03T20:17:37.490833",
          "status": "completed"
        },
        "tags": [],
        "id": "3pDRCaNk5Qu-"
      },
      "source": [
        "def collate_fn(batch):\n",
        "    return tuple(zip(*batch))\n",
        "\n",
        "def run_training():\n",
        "    if Kaggle:\n",
        "        device = torch.device('cuda:0')\n",
        "    else:\n",
        "        device = ('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    net.to(device)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=TrainGlobalConfig.batch_size,\n",
        "        sampler=RandomSampler(train_dataset),\n",
        "        pin_memory=False,\n",
        "        drop_last=True,\n",
        "        num_workers=TrainGlobalConfig.num_workers,\n",
        "        collate_fn=collate_fn,\n",
        "    )\n",
        "    val_loader = torch.utils.data.DataLoader(\n",
        "        validation_dataset, \n",
        "        batch_size=TrainGlobalConfig.batch_size,\n",
        "        num_workers=TrainGlobalConfig.num_workers,\n",
        "        shuffle=False,\n",
        "        sampler=SequentialSampler(validation_dataset),\n",
        "        pin_memory=False,\n",
        "        collate_fn=collate_fn,\n",
        "    )\n",
        "\n",
        "    fitter = Fitter(model=net, device=device, config=TrainGlobalConfig)\n",
        "    fitter.fit(train_loader, val_loader)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-12-03T20:17:40.490346Z",
          "iopub.status.busy": "2020-12-03T20:17:40.480631Z",
          "iopub.status.idle": "2020-12-03T20:17:44.356599Z",
          "shell.execute_reply": "2020-12-03T20:17:44.355423Z"
        },
        "papermill": {
          "duration": 4.767308,
          "end_time": "2020-12-03T20:17:44.356749",
          "exception": false,
          "start_time": "2020-12-03T20:17:39.589441",
          "status": "completed"
        },
        "tags": [],
        "id": "nVTdclME5Qu-"
      },
      "source": [
        "def get_net():\n",
        "    config = get_efficientdet_config('tf_efficientdet_d5')\n",
        "    net = EfficientDet(config, pretrained_backbone=False)\n",
        "    checkpoint = torch.load(os.path.join(PATH, 'nfl-models/efficientdet_d5-ef44aea8.pth'))\n",
        "    net.load_state_dict(checkpoint)\n",
        "    config.num_classes = 2\n",
        "    config.image_size = 512\n",
        "    net.class_net = HeadNet(config, num_outputs=config.num_classes, norm_kwargs=dict(eps=.001, momentum=.01))\n",
        "    return DetBenchTrain(net, config)\n",
        "\n",
        "net = get_net()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-12-03T20:17:46.495960Z",
          "iopub.status.busy": "2020-12-03T20:17:46.069898Z",
          "iopub.status.idle": "2020-12-03T21:15:33.319215Z",
          "shell.execute_reply": "2020-12-03T21:15:33.318628Z"
        },
        "papermill": {
          "duration": 3468.111783,
          "end_time": "2020-12-03T21:15:33.319336",
          "exception": false,
          "start_time": "2020-12-03T20:17:45.207553",
          "status": "completed"
        },
        "scrolled": true,
        "tags": [],
        "id": "lNN08JJW5Qu-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1a3c0f59-8b60-4dfc-f239-8efc68c15073"
      },
      "source": [
        "run_training()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitter prepared. Device is cuda\n",
            "\n",
            "2020-12-04T17:27:11.332093\n",
            "LR: 0.0001\n",
            "[RESULT]: Train. Epoch: 0, summary_loss: 67.75418, time: 1547.79430\n",
            "[RESULT]: Val. Epoch: 0, summary_loss: 1.40459, time: 361.47298\n",
            "\n",
            "2020-12-04T17:59:04.372166\n",
            "LR: 0.0001\n",
            "[RESULT]: Train. Epoch: 1, summary_loss: 0.77612, time: 1515.82745\n",
            "[RESULT]: Val. Epoch: 1, summary_loss: 0.62659, time: 86.71461\n",
            "\n",
            "2020-12-04T18:25:50.508281\n",
            "LR: 0.0001\n",
            "[RESULT]: Train. Epoch: 2, summary_loss: 0.41705, time: 1520.90600\n",
            "[RESULT]: Val. Epoch: 2, summary_loss: 0.51146, time: 86.85309\n",
            "\n",
            "2020-12-04T18:52:42.899482\n",
            "LR: 0.0001\n",
            "[RESULT]: Train. Epoch: 3, summary_loss: 0.31580, time: 1516.50657\n",
            "[RESULT]: Val. Epoch: 3, summary_loss: 0.48389, time: 85.59934\n",
            "\n",
            "2020-12-04T19:19:28.561006\n",
            "LR: 0.0001\n",
            "[RESULT]: Train. Epoch: 4, summary_loss: 0.26423, time: 1512.71367\n",
            "[RESULT]: Val. Epoch: 4, summary_loss: 0.50089, time: 85.98314\n",
            "\n",
            "2020-12-04T19:46:09.168559\n",
            "LR: 0.0001\n",
            "[RESULT]: Train. Epoch: 5, summary_loss: 0.23275, time: 1524.45355\n",
            "[RESULT]: Val. Epoch: 5, summary_loss: 0.50173, time: 86.88353\n",
            "\n",
            "2020-12-04T20:13:03.580526\n",
            "LR: 5e-05\n",
            "[RESULT]: Train. Epoch: 6, summary_loss: 0.18361, time: 1516.29875\n",
            "[RESULT]: Val. Epoch: 6, summary_loss: 0.51856, time: 86.30174\n",
            "\n",
            "2020-12-04T20:39:47.955239\n",
            "LR: 5e-05\n",
            "[RESULT]: Train. Epoch: 7, summary_loss: 0.16439, time: 1514.55115\n",
            "[RESULT]: Val. Epoch: 7, summary_loss: 0.53051, time: 85.09767\n",
            "\n",
            "2020-12-04T21:06:30.434422\n",
            "LR: 2.5e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-2f18cc448813>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrun_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-9ee9e8890509>\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mfitter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFitter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrainGlobalConfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0mfitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-6bc6a56ce785>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_loader, validation_loader)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m             \u001b[0msummary_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_one_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'[RESULT]: Train. Epoch: {self.epoch}, summary_loss: {summary_loss.avg:.5f}, time: {(time.time() - t):.5f}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-15-6bc6a56ce785>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[0;34m(self, train_loader)\u001b[0m\n\u001b[1;32m    106\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mboxes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0msummary_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-12-03T21:15:39.110558Z",
          "iopub.status.busy": "2020-12-03T21:15:39.109713Z",
          "iopub.status.idle": "2020-12-03T21:15:40.239972Z",
          "shell.execute_reply": "2020-12-03T21:15:40.239159Z"
        },
        "papermill": {
          "duration": 3.984352,
          "end_time": "2020-12-03T21:15:40.240095",
          "exception": false,
          "start_time": "2020-12-03T21:15:36.255743",
          "status": "completed"
        },
        "tags": [],
        "id": "TduA6fs65Qu-"
      },
      "source": [
        "# clearing working dir\n",
        "# be careful when running this code on local environment!\n",
        "# !rm -rf *\n",
        "# !mv * /tmp/train_images\n",
        "\n",
        "# import shutil\n",
        "# shutil.rmtree(out_dir)  "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}